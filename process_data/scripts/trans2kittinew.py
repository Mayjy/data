import os
import numpy as np
import shutil

def read_pcd_with_label(input_path):
    """è¯»å– PCD æ–‡ä»¶ï¼Œè¿”å›ç‚¹äº‘æ•°æ®å’Œæ ‡ç­¾"""
    with open(input_path, 'r') as f:
        lines = [line.strip() for line in f.readlines()]
    
    data_start = lines.index('DATA ascii') + 1
    
    points = []
    labels = []
    for line in lines[data_start:]:
        if not line:
            continue
        parts = line.split()
        if len(parts) >= 4:
            x, y, z = map(float, parts[:3])
            label = int(float(parts[3]))
            points.append([x, y, z])  # å»æ‰å¼ºåº¦ # å¼ºåº¦ä¸º 0
            labels.append(label)

    return np.array(points, dtype=np.float32), np.array(labels, dtype=np.uint32)


def convert_and_split_dataset(pcd_dir, output_root):
    """å°†æ‰€æœ‰ PCD æ–‡ä»¶åˆ†æˆä¸‰ä¸ªåºåˆ—ï¼ˆ00ã€01ã€02ï¼‰å¹¶è½¬æ¢ä¸º SemanticKITTI æ ¼å¼"""
    # æ‰€æœ‰ .pcd æ–‡ä»¶æ’åºååˆ†ç»„
    all_files = sorted([f for f in os.listdir(pcd_dir) if f.endswith('.pcd')])
    total = len(all_files)
    assert total == 1192, f"æœŸæœ› 1198 ä¸ªæ–‡ä»¶ï¼Œå®é™…æ‰¾åˆ° {total} ä¸ª"

    split_00 = all_files[:992]
    split_01 = all_files[992:1092]
    split_02 = all_files[1092:]

    splits = {
        "00": split_00,
        "01": split_01,
        "02": split_02
    }

    for seq_id, file_list in splits.items():
        print(f"ğŸ”§ æ­£åœ¨å¤„ç† sequence {seq_id}ï¼ˆ{len(file_list)} ä¸ªæ–‡ä»¶ï¼‰")

        velo_dir = os.path.join(output_root, "sequences", seq_id, "velodyne")
        label_dir = os.path.join(output_root, "sequences", seq_id, "labels")
        os.makedirs(velo_dir, exist_ok=True)
        os.makedirs(label_dir, exist_ok=True)

        for fname in file_list:
            input_path = os.path.join(pcd_dir, fname)
            points, labels = read_pcd_with_label(input_path)

            base_name = os.path.splitext(fname)[0]
            bin_path = os.path.join(velo_dir, f"{base_name}.bin")
            label_path = os.path.join(label_dir, f"{base_name}.label")

            points.tofile(bin_path)
            labels.tofile(label_path)

        print(f"âœ… Sequence {seq_id} å¤„ç†å®Œæˆï¼Œå·²å†™å…¥ {len(file_list)} ä¸ªæ–‡ä»¶")

def validate_sequences(output_root):
    """éªŒè¯æ¯ä¸ªåºåˆ—ä¸­çš„ .bin å’Œ .label æ–‡ä»¶æ˜¯å¦ä¸€ä¸€å¯¹åº”"""
    for seq in ["00", "01", "02"]:
        seq_dir = os.path.join(output_root, "sequences", seq)
        velo_dir = os.path.join(seq_dir, "velodyne")
        label_dir = os.path.join(seq_dir, "labels")

        bin_files = {os.path.splitext(f)[0] for f in os.listdir(velo_dir) if f.endswith('.bin')}
        label_files = {os.path.splitext(f)[0] for f in os.listdir(label_dir) if f.endswith('.label')}

        missing_bin = label_files - bin_files
        missing_label = bin_files - label_files

        if missing_bin or missing_label:
            print(f"âŒ Sequence {seq} æ–‡ä»¶ä¸åŒ¹é…")
            if missing_bin:
                print(f"  ç¼ºå¤± bin æ–‡ä»¶ï¼š{missing_bin}")
            if missing_label:
                print(f"  ç¼ºå¤± label æ–‡ä»¶ï¼š{missing_label}")
        else:
            print(f"âœ… Sequence {seq} éªŒè¯é€šè¿‡ï¼Œå…± {len(bin_files)} ä¸ªæ ·æœ¬")

if __name__ == "__main__":
    # ä¿®æ”¹è¿™é‡Œçš„è·¯å¾„ä¸ºä½ è£å‰ªå .pcd æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•
    input_pcd_dir = "/home/may/data/process_data/data/afterDBSCAN_dataset"
    output_root = "/home/may/data/process_data/data/Final_dataset/dataset"

    convert_and_split_dataset(input_pcd_dir, output_root)
    validate_sequences(output_root)
