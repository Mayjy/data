import os
import numpy as np

# ====== ä¿®æ”¹è¿™é‡Œçš„ç›®å½•è·¯å¾„ ======
input_dir = "process_data/data/dataset"               # è¾“å…¥æ–‡ä»¶å¤¹
output_dir = "process_data/data/aftercut_dataset"     # è¾“å‡ºæ–‡ä»¶å¤¹

too_few_points_files = []  # ç”¨æ¥è®°å½•ç‚¹æ•°å°‘äºŽ5000çš„æ–‡ä»¶åå’Œå¯¹åº”ç‚¹æ•°

def parse_pcd_header(lines):
    header = []
    data_start = 0
    for i, line in enumerate(lines):
        header.append(line)
        if line.strip().startswith("DATA"):
            data_start = i + 1
            break
    return header, data_start

def remove_outliers_by_percentile(points, lower_percentile=1, upper_percentile=99):
    cleaned_points = points.copy()
    for i in [0, 2]:  # åªå¤„ç† X (0) å’Œ Z (2)ï¼Œè·³è¿‡ Y (1)
        low = np.percentile(cleaned_points[:, i], lower_percentile)
        high = np.percentile(cleaned_points[:, i], upper_percentile)
        mask = (cleaned_points[:, i] >= low) & (cleaned_points[:, i] <= high)
        cleaned_points = cleaned_points[mask]
    return cleaned_points

def get_dynamic_bounds(points):
    min_bound = np.min(points[:, :3], axis=0)
    max_bound = np.max(points[:, :3], axis=0)
    range_ = max_bound - min_bound

    new_min = min_bound.copy()
    new_max = max_bound.copy()

    # ç¬¬ä¸€ä¸ªåæ ‡ï¼ˆXè½´ï¼‰ä¿ç•™ä¸­é—´ 70%ï¼ˆä¸¤è¾¹å„è£å‰ª 15%ï¼‰
    new_min[0] = min(-14, min_bound[0] + range_[0] * 0.15)
    new_max[0] = max(14, max_bound[0] - range_[0] * 0.15)

    # ç¬¬äºŒä¸ªåæ ‡ï¼ˆYè½´ï¼‰ä¿æŒä¸å˜

    # ç¬¬ä¸‰ä¸ªåæ ‡ï¼ˆZè½´ï¼‰ä¸‹è¾¹ç•Œå– max(åŽŸå§‹ min_z, 30.0)
    if range_[2] > 30:
        new_min[2] = max(min_bound[2]+range_[2]*0.3, 30.0)
    # new_max[2] ä¿æŒä¸å˜

    return new_min, new_max

def process_file(input_file, output_file):
    with open(input_file, 'r') as f:
        lines = f.readlines()

    header, data_start = parse_pcd_header(lines)
    point_lines = lines[data_start:]
    points = np.loadtxt(point_lines, dtype=np.float32)

    # å…ˆåŽ»é™¤ç¦»ç¾¤ç‚¹
    points = remove_outliers_by_percentile(points, 1, 99)

    # åˆ†ç¦»åæ ‡å’Œæ ‡ç­¾
    coords = points[:, :3]
    labels = points[:, 3].astype(int)

    # è®¡ç®—åŠ¨æ€è¾¹ç•Œ
    new_min, new_max = get_dynamic_bounds(points)

    # æ ‡ç­¾ä¸º0çš„ç‚¹æ ¹æ®èŒƒå›´ç­›é€‰
    mask_label0 = (labels == 0)
    mask_in_bound = np.all((coords >= new_min) & (coords <= new_max), axis=1)
    mask_keep_label0 = mask_label0 & mask_in_bound

    # æ ‡ç­¾ä¸º1æˆ–2çš„ç‚¹å…¨éƒ¨ä¿ç•™
    mask_keep_label12 = (labels == 1) | (labels == 2)

    # åˆå¹¶ä¿ç•™çš„ç‚¹
    mask_keep = mask_keep_label0 | mask_keep_label12
    filtered_points = points[mask_keep]

    # ç»Ÿè®¡ç‚¹æ•°å°‘äºŽ 5000 çš„æ–‡ä»¶ï¼Œå­˜æ–‡ä»¶åå’Œç‚¹æ•°
    if filtered_points.shape[0] < 5000:
        too_few_points_files.append((os.path.basename(input_file), filtered_points.shape[0]))

    # ä¿®æ”¹ header ä¸­ POINTS å’Œ WIDTH
    new_header = []
    for line in header:
        if line.startswith("POINTS"):
            new_header.append(f"POINTS {filtered_points.shape[0]}\n")
        elif line.startswith("WIDTH"):
            new_header.append(f"WIDTH {filtered_points.shape[0]}\n")
        else:
            new_header.append(line)

    os.makedirs(os.path.dirname(output_file), exist_ok=True)

    with open(output_file, 'w') as f:
        f.writelines(new_header)
        np.savetxt(f, filtered_points, fmt="%.6f %.6f %.6f %d")

    print(f"âœ… å·²å¤„ç†ï¼š{input_file}")
    print(f"   ç‚¹æ•°ä»Ž {points.shape[0]} -> {filtered_points.shape[0]}")

def main():
    for filename in os.listdir(input_dir):
        if filename.endswith(".pcd"):
            input_file = os.path.join(input_dir, filename)
            output_file = os.path.join(output_dir, filename)
            process_file(input_file, output_file)

    print("âœ… æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆï¼")
    if too_few_points_files:
        print("\nâš ï¸ ä»¥ä¸‹æ–‡ä»¶å¤„ç†åŽç‚¹æ•°å°‘äºŽ 5000ï¼š")
        for fname, count in too_few_points_files:
            print(f" - {fname}: {count} points")
    else:
        print("\nðŸŽ‰ æ‰€æœ‰æ–‡ä»¶ç‚¹æ•°å‡ >= 5000")

if __name__ == "__main__":
    main()
